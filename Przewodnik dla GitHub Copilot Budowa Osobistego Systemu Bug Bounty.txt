Przewodnik dla GitHub Copilot: Budowa Osobistego Systemu Bug BountyKontekst Projektu dla CopilotaCel: Tworzymy aplikację "Bug Bounty Orchestrator". Jest to osobiste narzędzie do automatyzacji procesu wyszukiwania podatności w aplikacjach webowych. System będzie zarządzał celami, uruchamiał skanowania i agregował wyniki.Architektura:Rdzeń: Monolityczna aplikacja backendowa w Pythonie z użyciem frameworka FastAPI.Narzędzia Skanujące: Zewnętrzne narzędzia open-source (subfinder, httpx, nmap, nuclei) uruchamiane w odizolowanych kontenerach Docker.Orkiestracja: Aplikacja FastAPI będzie asynchronicznie wywoływać i zarządzać kontenerami Docker za pomocą biblioteki asyncio.subprocess.Baza Danych: PostgreSQL do przechowywania celów, zasobów i wyników.Interfejs: System będzie sterowany przez API (bez interfejsu graficznego w tej fazie).Konwencje Kodowania:Używaj type hints w całym kodzie Python.Stosuj modele Pydantic do walidacji danych wejściowych i wyjściowych API.Wszystkie operacje I/O (baza danych, wywołania subprocessów) muszą być asynchroniczne (async/await).Stosuj czytelne nazwy zmiennych i funkcji.Dodawaj docstringi w stylu Google do kluczowych funkcji.Faza 1: Przygotowanie Środowiska i ProjektuKrok 1.1: Struktura ProjektuUtwórz następującą strukturę folderów i plików:bug-bounty-orchestrator/
├── app/
│   ├── __init__.py
│   ├── main.py             # Główny plik aplikacji FastAPI
│   ├── api/
│   │   ├── __init__.py
│   │   └── v1/
│   │       ├── __init__.py
│   │       └── endpoints/
│   │           ├── __init__.py
│   │           └── scans.py    # Endpointy API do zarządzania skanami
│   ├── core/
│   │   ├── __init__.py
│   │   └── scanner.py      # Logika uruchamiania narzędzi w Dockerze
│   ├── db/
│   │   ├── __init__.py
│   │   ├── base.py         # Konfiguracja połączenia z bazą danych
│   │   └── models.py       # Modele SQLAlchemy
│   └── schemas/
│       ├── __init__.py
│       └── scan.py         # Schematy Pydantic
├──.env                    # Zmienne środowiskowe
├──.gitignore
├── Dockerfile              # Do budowy obrazu aplikacji
├── docker-compose.yml      # Do uruchamiania lokalnego
└── pyproject.toml          # Konfiguracja zależności (Poetry)
Krok 1.2: Konfiguracja ZależnościZainicjuj projekt poetry i dodaj wymagane biblioteki.Bashpoetry init -n
poetry add "fastapi[all]" sqlalchemy "asyncpg[sa]" alembic python-dotenv
Krok 1.3: Konfiguracja Bazy Danych (Aiven)Załóż darmowe konto na Aiven.io.1Utwórz darmową instancję PostgreSQL.Skopiuj Service URI (ciąg połączeniowy) do pliku .env.Plik: .envDATABASE_URL="postgres://avnadmin:TWOJE_HASLO@twoj-host-p.aivencloud.com:PORT/defaultdb?sslmode=require"
Faza 2: Rdzeń Aplikacji - Backend FastAPIKrok 2.1: Modele Bazy DanychPlik: app/db/models.py▶️ PROMPT DLA COPILOTA:"Using SQLAlchemy 2.0 declarative mapping with type annotations, create database models for a bug bounty scanning application. I need four tables:Target: should have an id (UUID, primary key), domain_name (string, unique), and created_at (timestamp).Scan: should have an id (UUID, primary key), a foreign key to Target, a status (string), created_at, and completed_at (nullable timestamp).Asset: should have an id (UUID, primary key), a foreign key to Scan, host (string), ip_address (nullable string), technologies (JSONB), and ports (JSONB).Vulnerability: should have an id (UUID, primary key), a foreign key to Asset, template_id (string), severity (string), description (text), and full_finding (JSONB).Use sqlalchemy.dialects.postgresql.UUID and JSONB types."Krok 2.2: Konfiguracja Połączenia z Bazą DanychPlik: app/db/base.py▶️ PROMPT DLA COPILOTA:"Create a database connection setup for a FastAPI application using SQLAlchemy 2.0 async engine.Load the DATABASE_URL from environment variables using python-dotenv.Create an async_engine using create_async_engine.Create an AsyncSessionLocal session factory using async_sessionmaker.Create a Base declarative base class."Krok 2.3: Schematy PydanticPlik: app/schemas/scan.py▶️ PROMPT DLA COPILOTA:"Create Pydantic models for my bug bounty API.ScanCreate: A model for creating a new scan, it should only accept a domain (string).ScanResponse: A model for the response after creating a scan, it should include scan_id (UUID) and a message (string).ScanStatus: A model to show the status of a scan, including scan_id (UUID) and status (string).AssetResponse: A model for returning discovered assets, including host (string) and technologies (dict).VulnerabilityResponse: A model for returning found vulnerabilities, including host (string), template_id (string), and severity (string)."Krok 2.4: Logika Skanera (Rdzeń Orkiestracji)To jest najważniejsza część. Tutaj zaimplementujemy logikę asynchronicznego uruchamiania kontenerów Docker.Plik: app/core/scanner.py▶️ PROMPT DLA COPILOTA:"Create a Python class ScannerService that runs security tools in Docker asynchronously.The class should have an __init__ method that takes an asyncpg database session.Create an async method _run_command that takes a command as a list of strings. It should use asyncio.create_subprocess_exec to run the command, capture stdout and stderr, and wait for it to complete.2 It should return the decoded stdout.Create an async method run_subfinder that takes a domain string. It should construct and run the docker run --rm projectdiscovery/subfinder -d {domain} -json command.3 It should parse the JSON output line by line and return a list of subdomains.Create an async method run_httpx that takes a list of subdomains. It should pass the list to the docker run --rm -i projectdiscovery/httpx -json command via stdin.6 It should parse the JSON output and return a list of active hosts with their technologies.Create an async method run_nuclei that takes a list of active hosts. It should pass them to docker run --rm -i projectdiscovery/nuclei -json via stdin.8 It should parse the JSON output and return a list of found vulnerabilities.Create a main orchestrator method start_full_scan that takes a scan_id and domain. This method should sequentially call run_subfinder, run_httpx, and run_nuclei, passing the results from one step to the next. After each step, it should update the scan status and save the results (assets, vulnerabilities) to the database."Krok 2.5: Endpointy APIPlik: app/api/v1/endpoints/scans.py▶️ PROMPT DLA COPILOTA:"Create a FastAPI APIRouter for managing scans.Import necessary dependencies, including APIRouter, Depends, BackgroundTasks, schemas, and the ScannerService.Create a dependency function get_db to provide a database session.Implement a POST / endpoint to create a new scan. It should accept a ScanCreate payload. It should create Target and Scan records in the database, then use BackgroundTasks to add the scanner_service.start_full_scan task to run in the background. It should return a ScanResponse with the new scan_id.Implement a GET /{scan_id}/status endpoint that retrieves and returns the current status of a scan from the database as a ScanStatus object.Implement a GET /{scan_id}/results/vulnerabilities endpoint that retrieves all vulnerabilities associated with a completed scan and returns them as a list of VulnerabilityResponse objects."Krok 2.6: Główny Plik AplikacjiPlik: app/main.py▶️ PROMPT DLA COPILOTA:"Create the main FastAPI application file.Import FastAPI.Import the scans router from app.api.v1.endpoints.Create the app instance of FastAPI.Include the scans router with a prefix /api/v1/scans.Add a root endpoint GET / that returns {'status': 'ok'}.Add a health check endpoint GET /healthz that returns 200 OK. This will be used to keep the service alive on Render.com.10"Faza 3: Konteneryzacja i WdrożenieKrok 3.1: DockerfilePlik: Dockerfile▶️ PROMPT DLA COPILOTA:"Create a multi-stage Dockerfile for a Python FastAPI application using Poetry.Builder Stage: Start from a python:3.11-slim image. Set up a working directory. Install poetry. Copy pyproject.toml and poetry.lock, then run poetry install without creating a virtual environment and with --no-dev.Final Stage: Start from a python:3.11-slim image. Create a non-root user. Copy the installed packages from the builder stage. Copy the application code (./app). Set the CMD to run the application using uvicorn app.main:app --host 0.0.0.0 --port 8000."Krok 3.2: Docker ComposePlik: docker-compose.yml▶️ PROMPT DLA COPILOTA:"Create a docker-compose.yml file for local development.It should define one service called api.The api service should build from the local Dockerfile.It should load environment variables from the .env file.It should map port 8000 on the host to port 8000 in the container.It should mount the local ./app directory into /app in the container for live reloading."Krok 3.3: Wdrożenie na Render.comUtwórz nowe repozytorium na GitHub i wypchnij swój kod.Zaloguj się na(https://render.com) i utwórz nową usługę "Web Service".Połącz swoje repozytorium GitHub.W ustawieniach wdrożenia:Environment: Wybierz Docker.Health Check Path: Ustaw na /healthz.10Environment Variables: Dodaj DATABASE_URL i wklej wartość z Twojego pliku .env.Uruchom wdrożenie.Krok 3.4: Konfiguracja Mechanizmu "Keep-Alive"Aby zapobiec usypianiu darmowej instancji Render, skonfiguruj zewnętrzny monitoring.11Załóż darmowe konto na(https://uptimerobot.com/).Dodaj nowy monitor:Monitor Type: HTTP(s)URL: Adres URL Twojej wdrożonej aplikacji na Render.com, zakończony ścieżką /healthz (np. https://twoja-aplikacja.onrender.com/healthz).Monitoring Interval: Ustaw na 5 minutes.Zapisz monitor. Usługa będzie teraz regularnie odpytywana, co zapobiegnie jej uśpieniu.Po wykonaniu tych kroków będziesz mieć w pełni działający, zautomatyzowany system do wyszukiwania podatności, zbudowany od podstaw z pomocą GitHub Copilot i działający w chmurze bez żadnych kosztów.